# Gesture-Triggered Autonomous Bubble System

An interactive visual system built using **MediaPipe**, **Python**, and **TouchDesigner** that creates autonomous digital bubbles through intentional human gestures.

---

## ğŸ¯ Aim of the Project

To design an event-based interaction system where human gestures act as a **creation trigger** rather than continuous control.  
A bubble is created only at the moment a specific gesture combination occurs and then behaves independently.

---

## ğŸ§  Project Concept Overview

The system detects:

- Hand positions (left and right)
- Specific hand gestures (OK gesture)
- Facial input (mouth open)

When a defined gesture combination (e.g., **OK gesture + mouth open**) is detected, a bubble is spawned at the exact hand position **at that moment**.

After creation:

- The bubble no longer follows the body
- It moves autonomously
- User input is no longer required

---

## ğŸ”¬ System Architecture

The project is divided into logical layers:

### 1ï¸âƒ£ Input Layer â€“ Human Body to Data
- MediaPipe hand tracking
- Face landmark detection
- Continuous and noisy real-time data

### 2ï¸âƒ£ Logic Layer â€“ Gesture Interpretation
- Filters accidental motion
- Detects intentional gesture combinations
- Generates a short trigger pulse (0 â†’ 1 â†’ 0)

### 3ï¸âƒ£ Spawn & Detachment Layer
- Samples hand X/Y only once
- Stores and holds the position
- Detaches visuals from live body data

### 4ï¸âƒ£ Visual Behavior Layer
- Autonomous floating motion
- Noise-driven movement
- Smooth fade-in and fade-out

---

## ğŸ«§ Visual Behavior

- Natural drifting motion
- Independent lifecycle
- Optional audio reactivity
- No continuous body dependency

---

## âš ï¸ Design Philosophy

Traditional systems rely on continuous control.  
This project intentionally avoids that.

Instead, it explores **event-based interaction**, transforming the user from an operator into a performer.

---

## âœ… Expected Output

### Functional
- No visuals at rest
- Bubble appears only after valid gesture
- Bubble remains after gesture release
- Autonomous motion after creation

### Visual
- Minimal bubble design
- Smooth animation
- Clean detachment from live tracking

### Conceptual
- Gesture-based event triggering
- Expressive interaction
- Foundation for interactive installations

---

## ğŸ¨ Applications

- Interactive art installations
- Live performance visuals
- Gesture-based creative tools
- Experimental HCI research
- Audio-visual environments

---

## ğŸ› ï¸ Tools & Technologies

- **Python**
- **MediaPipe**
- **TouchDesigner 2025.32050**
- **OSC Communication**

---

## ğŸ§© Conclusion

This project demonstrates how intentional gestures can create expressive autonomous digital behavior.  
By separating creation from control, the system enables more natural and meaningful interaction.

---

## ğŸ“½ï¸ Demo
(Add video or screenshots here)
